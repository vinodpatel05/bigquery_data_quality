{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNz_7idNEdlE"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXbw-R0ZGiWf"
      },
      "source": [
        "#Data Quality and Validation in BigQuery using BigFrames\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fapplying-llms-to-data%2Fsemantic-search-in-bigquery%2Fstackoverflow_questions_semantic_search.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/bigquery/import?url=https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/bigquery/v1/32px.svg\" alt=\"BigQuery Studio logo\"><br> Open in BigQuery Studio\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/applying-llms-to-data/semantic-search-in-bigquery/stackoverflow_questions_semantic_search.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qTZ1THsriwh"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Vinod Patel](https://github.com/sethijaideep) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cGtn8TvG7SB"
      },
      "source": [
        "## Overview\n",
        "This notebook demonstrates how to perform essential data quality tasks directly within BigQuery,leveraging the `bigframes` library for a familiar pandas-like experience on large datasets.\n",
        "\n",
        "Data quality is a critical aspect of any data-driven initiative, especially in machine learning and analytics. Poor data quality can lead to inaccurate insights, flawed models, and unreliable decisions. This notebook provides a practical guide to:\n",
        "\n",
        "1.  **Data Profiling**: Understanding the structure, content, and quality of your data through descriptive statistics.\n",
        "2.  **Anomaly Detection**: Identifying unusual or suspicious data points that deviate from expected patterns.\n",
        "3.  **Data Cleansing & Validation**: Implementing techniques to correct errors, handle inconsistencies, and ensure data conforms to predefined rules.\n",
        "\n",
        "By using `bigframes`, these operations are executed efficiently on your BigQuery data, avoiding the need to move large datasets out of the data warehouse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf3ioTDBzuHR"
      },
      "source": [
        "## About the dataset\n",
        "\n",
        "This notebook utilizes a publicly available dataset from Google Cloud's BigQuery Public Datasets program:\n",
        "\n",
        "**Dataset Name**: `austin_bikeshare`\n",
        "**Table Name**: `bikeshare_trips`\n",
        "\n",
        "This dataset contains historical trip data for the Austin B-cycle bike-sharing program. It includes information such as:\n",
        "\n",
        "* `trip_id`: Unique identifier for each trip.\n",
        "* `subscriber_type`: Type of user (e.g., 'Subscriber', 'Customer').\n",
        "* `start_time`, `end_time`: Timestamp of trip start and end.\n",
        "* `duration_minutes`: Duration of the trip in minutes.\n",
        "* `start_station_name`, `end_station_name`: Names of the start and end stations.\n",
        "* `bike_id`: Identifier for the bike used.\n",
        "* `bike_type`: type of the bike used.\n",
        "\n",
        "You can explore this dataset directly in the BigQuery console from [here](https://console.cloud.google.com/bigquery?project=bigquery-public-data&ws=!1m5!1m4!4m3!1sbigquery-public-data!2saustin_bikeshare!3sbikeshare_trips)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation"
      ],
      "metadata": {
        "id": "eohJOoKdeN04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bigframes  --quiet"
      ],
      "metadata": {
        "id": "Ou_-YbXWeWhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58707a750154"
      },
      "source": [
        "### Colab only\n",
        "\n",
        "Uncomment and run the following cell to restart the kernel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f200f10a1da3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "# import IPython\n",
        "\n",
        "# app = IPython.Application.instance()\n",
        "# app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF1j6f9HApxa"
      },
      "source": [
        "# Environment setup\n",
        "\n",
        "Complete the tasks in this section to set up your environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq7zKYWelRQP"
      },
      "source": [
        "### Set up your Google Cloud project\n",
        "\n",
        "**The following steps are required, regardless of your notebook environment.**\n",
        "\n",
        "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 credit towards your compute/storage costs.\n",
        "\n",
        "2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "3. [Click here](https://console.cloud.google.com/flows/enableapi?apiid=bigquery.googleapis.com,bigqueryconnection.googleapis.com,cloudfunctions.googleapis.com,run.googleapis.com,artifactregistry.googleapis.com,cloudbuild.googleapis.com,cloudresourcemanager.googleapis.com) to enable the following APIs:\n",
        "\n",
        "  * BigQuery API\n",
        "  * BigQuery Connection API\n",
        "\n",
        "4. If you are running this notebook locally, install the [Cloud SDK](https://cloud.google.com/sdk)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "If you don't know your project ID, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM1iC_MfAts1",
        "outputId": "9f6d851d-9132-417a-b222-9367f699f61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "#### Authenticate your Google Cloud account\n",
        "\n",
        "Depending on your Jupyter environment, you might have to manually authenticate. Follow the relevant instructions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ccc9e52986"
      },
      "source": [
        "**Vertex AI Workbench**\n",
        "\n",
        "Do nothing, you are already authenticated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**Local JupyterLab instance**\n",
        "\n",
        "Uncomment and run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254614fa0c46"
      },
      "outputs": [],
      "source": [
        "# ! gcloud auth login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef21552ccea8"
      },
      "source": [
        "**Colab**\n",
        "\n",
        "Uncomment and run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "603adbbf0532"
      },
      "outputs": [],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "JgnQWOJgjtbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bigframes.pandas as bf\n",
        "import bigframes.bigquery as bq\n",
        "from google.cloud import bigquery  # Still useful for some direct BQ client operations like INFORMATION_SCHEMA\n",
        "import pandas as pd  # For local display if needed\n",
        "import datetime # For timestamp comparisons"
      ],
      "metadata": {
        "id": "gJlPSGoCg0FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set project id using bigframe option\n",
        "bf.options.bigquery.project=PROJECT_ID"
      ],
      "metadata": {
        "id": "mLVcfAuwgicq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load BigQuery table into a bigframe\n"
      ],
      "metadata": {
        "id": "tU4Jdz3Dkq7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Public dataset details\n",
        "BQ_PROJECT_ID = \"bigquery-public-data\"\n",
        "DATASET_ID = \"austin_bikeshare\"\n",
        "TABLE_ID = \"bikeshare_trips\"\n",
        "\n",
        "# Full table reference for `bigframes`\n",
        "FULL_TABLE_REF = f\"{BQ_PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# Initialize BigQuery client for direct SQL (e.g., INFORMATION_SCHEMA)\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "print(f\"Connected to BigQuery via bigframes.\")\n",
        "\n",
        "# Load the BigQuery table into a bigframes DataFrame\n",
        "try:\n",
        "    df = bf.read_gbq_table(FULL_TABLE_REF)\n",
        "    print(f\"Successfully loaded BigQuery table into bigframes DataFrame. Shape: {df.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading table: {e}\")\n",
        "    print(\"Please ensure the table exists and you have the necessary permissions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "xadnJgiY3Zrv",
        "outputId": "b5a72313-33b8-4766-8a62-afc2717eb504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to BigQuery via bigframes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 9a0060d5-49da-4c00-9b37-cfd625ce20d5 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=vinodpatel05-handson-project&j=bq:US:9a0060d5-49da-4c00-9b37-cfd625ce20d5&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded BigQuery table into bigframes DataFrame. Shape: (2271152, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Data Profiling\n",
        " Data profiling is the process of examining the data available in an information source and collecting statistics and information about that data. It helps us understand the structure, content, and quality of our dataset."
      ],
      "metadata": {
        "id": "Gu5W-UVU2XNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Table Overview (Row Count, Column Names, Data Types)\n",
        "We'll start by getting a high-level overview of the DataFrame, including its dimensions and column types."
      ],
      "metadata": {
        "id": "cFB5VQABlL-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 1.1 Table Overview ---\")\n",
        "print(f\"Total rows: {df.shape[0]}\")\n",
        "print(\"\\nColumn information:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVlaYOtxmDap",
        "outputId": "fe85f160-8c64-48b2-e716-5110c4512352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1.1 Table Overview ---\n",
            "Total rows: 2271152\n",
            "\n",
            "Column information:\n",
            "<class 'bigframes.dataframe.DataFrame'>\n",
            "Index: 2271152 entries, 0 to 2271151\n",
            "Data columns (total 10 columns):\n",
            "  #  Column              Dtype\n",
            "---  ------------------  ------------------------------\n",
            "  0  trip_id             string\n",
            "  1  subscriber_type     string\n",
            "  2  bike_id             string\n",
            "  3  bike_type           string\n",
            "  4  start_time          timestamp[us, tz=UTC][pyarrow]\n",
            "  5  start_station_id    Int64\n",
            "  6  start_station_name  string\n",
            "  7  end_station_id      string\n",
            "  8  end_station_name    string\n",
            "  9  duration_minutes    Int64\n",
            "dtypes: Int64(2), string(7), timestamp[us, tz=UTC][pyarrow](1)\n",
            "memory usage: 199861376 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Column-wise Profiling (Descriptive Statistics)\n",
        "\n",
        " We'll examine key statistics for individual columns, focusing on numerical, string, and timestamp types."
      ],
      "metadata": {
        "id": "NuPpBP_Z2xSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  1.2.1 Numeric Column: `duration_minutes`\n",
        "\n",
        "This provides count, mean, standard deviation, min, max, and quartiles for numeric columns."
      ],
      "metadata": {
        "id": "1mbVV-mDnWCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 1.2.1 Numeric Column: `duration_minutes` ---\")\n",
        "# Describe provides basic stats including count, mean, std, min, max, and quartiles\n",
        "print(df['duration_minutes'].describe().to_markdown())\n",
        "\n",
        "# Check nulls specifically\n",
        "print(f\"\\nNull count for 'duration_minutes': {df['duration_minutes'].isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQK9OTqtn06J",
        "outputId": "67849a7a-b089-4f86-a3ce-c461f8562601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1.2.1 Numeric Column: `duration_minutes` ---\n",
            "|       |   duration_minutes |\n",
            "|:------|-------------------:|\n",
            "| count |        2.27115e+06 |\n",
            "| mean  |       28.7192      |\n",
            "| std   |      125.317       |\n",
            "| min   |        2           |\n",
            "| 25%   |        6           |\n",
            "| 50%   |       12           |\n",
            "| 75%   |       27           |\n",
            "| max   |    34238           |\n",
            "\n",
            "Null count for 'duration_minutes': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  1.2.2 String Column: `start_station_name`\n",
        "For string columns, we look at non-null count, distinct count, and top occurring values."
      ],
      "metadata": {
        "id": "Lkzdy6Wuop3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 1.2.2 String Column: `start_station_name` ---\")\n",
        "print(f\"Non-null count: {df['start_station_name'].count()}\")\n",
        "print(f\"Null count: {df['start_station_name'].isnull().sum()}\")\n",
        "print(f\"Distinct count: {df['start_station_name'].nunique()}\")\n",
        "print(\"\\nTop 10 distinct values:\")\n",
        "print(df['start_station_name'].value_counts().head(10).to_markdown())\n",
        "\n",
        "# Average and max length (using bigframes.Series.str methods)\n",
        "print(f\"\\nAverage length: {df['start_station_name'].str.len().mean()}\")\n",
        "print(f\"Max length: {df['start_station_name'].str.len().max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW5b6Xl5n6bU",
        "outputId": "1761bb95-35c1-4d92-fb1f-d609049a35c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1.2.2 String Column: `start_station_name` ---\n",
            "Non-null count: 2271152\n",
            "Null count: 0\n",
            "Distinct count: 201\n",
            "\n",
            "Top 10 distinct values:\n",
            "| start_station_name                     |   count |\n",
            "|:---------------------------------------|--------:|\n",
            "| 21st/Speedway @ PCL                    |  108559 |\n",
            "| 21st & Speedway @PCL                   |   71145 |\n",
            "| Dean Keeton/Speedway                   |   65066 |\n",
            "| Zilker Park                            |   49294 |\n",
            "| 26th/Nueces                            |   44179 |\n",
            "| 21st/Guadalupe                         |   43716 |\n",
            "| Dean Keeton/Whitis                     |   43215 |\n",
            "| Guadalupe/West Mall @ University Co-op |   38708 |\n",
            "| Rainey/Cummings                        |   37040 |\n",
            "| Riverside/South Lamar                  |   36653 |\n",
            "\n",
            "Average length: 20.662780386341275\n",
            "Max length: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  1.2.3 Timestamp Column: `start_time`\n",
        "For timestamp columns, we examine non-null count, min/max dates, and the overall time range."
      ],
      "metadata": {
        "id": "GrP4jvNIpPav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 1.2.3 Timestamp Column: `start_time` ---\")\n",
        "print(f\"Non-null count: {df['start_time'].count()}\")\n",
        "print(f\"Null count: {df['start_time'].isnull().sum()}\")\n",
        "min_time = df['start_time'].min()\n",
        "max_time = df['start_time'].max()\n",
        "print(f\"Min datetime: {min_time}\")\n",
        "print(f\"Max datetime: {max_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiexWt3TpRtH",
        "outputId": "ebd1071d-4d41-4366-bafa-af08e69da52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1.2.3 Timestamp Column: `start_time` ---\n",
            "Non-null count: 2271152\n",
            "Null count: 0\n",
            "Min datetime: 2013-12-12 16:48:46+00:00\n",
            "Max datetime: 2024-06-30 23:44:03+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  2.Identifying Anomalies\n",
        "\n",
        "Anomalies are data points that deviate significantly from the expected pattern or distribution. Identifying them is crucial for data quality, as they can indicate errors or unusual events.\n"
      ],
      "metadata": {
        "id": "1sYByoC8qM6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  2.1 Outliers in Numeric Data: `duration_minutes`\n",
        "We can identify outliers using statistical methods like Z-scores. A Z-score measures how many standard deviations an element is from the mean."
      ],
      "metadata": {
        "id": "PunEJ6NA3TLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 2.1 Outliers in Numeric Data: `duration_minutes` ---\")\n",
        "\n",
        "# Calculate mean and standard deviation using bigframes\n",
        "mean_duration = df['duration_minutes'].mean()\n",
        "std_duration = df['duration_minutes'].std()\n",
        "\n",
        "# Calculate Z-score for each trip\n",
        "df_with_zscore = df.assign(\n",
        "    z_score=(df['duration_minutes'] - mean_duration) / std_duration\n",
        ")\n",
        "\n",
        "# Filter for outliers: Z-score > 5 (extreme) or duration less than 1 minute (suspicious)\n",
        "numeric_outliers = df_with_zscore[\n",
        "    (df_with_zscore['z_score'].abs() > 5) | (df_with_zscore['duration_minutes'] < 1)\n",
        "]\n",
        "\n",
        "print(\"Top 10 numeric outliers:\")\n",
        "print(numeric_outliers[['trip_id', 'duration_minutes', 'z_score']].head(10).to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "DGF7aFYZqEGk",
        "outputId": "4908b14e-4e37-4dcf-cb5d-f632ce59f5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2.1 Outliers in Numeric Data: `duration_minutes` ---\n",
            "Top 10 numeric outliers:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 8f53b797-f7bb-496e-9b18-23c6217a6f42 is DONE. 76.8 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=vinodpatel05-handson-project&j=bq:US:8f53b797-f7bb-496e-9b18-23c6217a6f42&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       trip_id  duration_minutes    z_score\n",
              "238   27949072               664   5.069404\n",
              "507   19610941              1776  13.942925\n",
              "553   19017035               694   5.308798\n",
              "694   23639366               854   6.585563\n",
              "1115  18941270               797   6.130715\n",
              "1466  28792962              1091   8.476772\n",
              "1709  17541702              3998  31.674006\n",
              "1760  29665060               773   5.939201\n",
              "2029  25941849               860   6.633442\n",
              "2032  27229355              1054    8.18152\n",
              "\n",
              "[10 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trip_id</th>\n",
              "      <th>duration_minutes</th>\n",
              "      <th>z_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>27949072</td>\n",
              "      <td>664</td>\n",
              "      <td>5.069404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>19610941</td>\n",
              "      <td>1776</td>\n",
              "      <td>13.942925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>19017035</td>\n",
              "      <td>694</td>\n",
              "      <td>5.308798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>23639366</td>\n",
              "      <td>854</td>\n",
              "      <td>6.585563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>18941270</td>\n",
              "      <td>797</td>\n",
              "      <td>6.130715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>28792962</td>\n",
              "      <td>1091</td>\n",
              "      <td>8.476772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1709</th>\n",
              "      <td>17541702</td>\n",
              "      <td>3998</td>\n",
              "      <td>31.674006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>29665060</td>\n",
              "      <td>773</td>\n",
              "      <td>5.939201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2029</th>\n",
              "      <td>25941849</td>\n",
              "      <td>860</td>\n",
              "      <td>6.633442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>27229355</td>\n",
              "      <td>1054</td>\n",
              "      <td>8.18152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 3 columns</p>\n",
              "</div>[10 rows x 3 columns in total]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Inconsistent String Values: `subscriber_type`\n",
        "Inconsistent string values often arise from typos, different casing, or multiple ways of representing the same concept. We can identify rare occurrences."
      ],
      "metadata": {
        "id": "rTOt8NBXqtRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 2.2 Inconsistent String Values: `subscriber_type` ---\")\n",
        "\n",
        "# Get value counts and filter for rare ones\n",
        "inconsistent_types = df['subscriber_type'].value_counts()\n",
        "rare_types = inconsistent_types[inconsistent_types < 100] # Adjust threshold as needed\n",
        "\n",
        "if not rare_types.empty:\n",
        "    print(\"Rare 'subscriber_type' values (less than 100 occurrences):\")\n",
        "    print(rare_types.to_markdown())\n",
        "else:\n",
        "    print(\"No rare 'subscriber_type' values found below the threshold.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqzTg14VqYm7",
        "outputId": "53948b98-8b77-4639-ffa0-2f195cfaebce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2.2 Inconsistent String Values: `subscriber_type` ---\n",
            "Rare 'subscriber_type' values (less than 100 occurrences):\n",
            "| subscriber_type                                    |   count |\n",
            "|:---------------------------------------------------|--------:|\n",
            "| Aluminum Access                                    |      96 |\n",
            "| Local365 Youth with helmet (age 13-17 riders)      |      91 |\n",
            "| Madtown Monthly                                    |      63 |\n",
            "| Annual Pass (Original)                             |      27 |\n",
            "| FunFunFun Fest 3 Day Pass                          |      27 |\n",
            "| Annual Plus Membership                             |      26 |\n",
            "| Republic Rider                                     |      16 |\n",
            "| Membership: pay once  one-year commitment          |      13 |\n",
            "| Denver B-cycle Founder                             |      12 |\n",
            "| Heartland Pass (Annual Pay)                        |      12 |\n",
            "| UT Student Membership                              |       9 |\n",
            "| Annual Membership                                  |       7 |\n",
            "| RideScout Single Ride                              |       4 |\n",
            "| Local365 Youth (age 13-17 riders)- 1/2 off Special |       3 |\n",
            "| Annual Pass (30 minute)                            |       2 |\n",
            "| Membership: pay once, one-year commitment          |       2 |\n",
            "| 24-Hour Membership                                 |       1 |\n",
            "| Heartland Pass (Monthly Pay)                       |       1 |\n",
            "| RESTRICTED                                         |       1 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Date/Time Anomalies: `start_time`\n",
        "Date/time anomalies could include dates far in the past or future, or times that are illogical for the context (e.g., trip start time before the bikeshare system existed)."
      ],
      "metadata": {
        "id": "H4VjM-2GrAIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 2.3 Date/Time Anomalies: `start_time` ---\")\n",
        "\n",
        "# Filter for dates before the bikeshare system (approx 2013) or in the future\n",
        "date_anomalies = df[\n",
        "    (df['start_time'] < pd.Timestamp('2013-01-01', tz='UTC')) |\n",
        "    (df['start_time'] > pd.Timestamp.now(tz='UTC'))\n",
        "]\n",
        "\n",
        "if not date_anomalies.empty:\n",
        "    print(\"Top 10 date/time anomalies in 'start_time':\")\n",
        "    print(date_anomalies[['trip_id', 'start_time']].head(10).to_markdown(index=False))\n",
        "else:\n",
        "    print(\"No date/time anomalies found based on the defined criteria.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEgzjKFGqwdV",
        "outputId": "75ae1e2a-4e64-457e-d849-0fcc189648c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2.3 Date/Time Anomalies: `start_time` ---\n",
            "No date/time anomalies found based on the defined criteria.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Data Cleansing and Validation\n",
        "Data cleansing involves fixing identified errors and inconsistencies, while validation ensures data conforms to defined rules and constraints. These operations typically result in a new, cleaner version of your dataset."
      ],
      "metadata": {
        "id": "6rQoggX3rK7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Handling NULLs: `end_station_id`\n",
        "Missing values (NULLs) can be handled by imputation (filling with a default value) or removal. Here, we'll fill with a placeholder."
      ],
      "metadata": {
        "id": "-af_pfRj327C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3.1 Handling NULLs: `end_station_id` ---\")\n",
        "\n",
        "# Create a new Series with nulls filled\n",
        "cleaned_end_station_name = df['end_station_id'].fillna('UNKNOWN_STATION_ID')\n",
        "\n",
        "# Display a sample of the original and cleaned column\n",
        "sample_df_nulls = df[df['end_station_id'].isnull()][['trip_id', 'end_station_id']].head(5)\n",
        "sample_df_nulls = sample_df_nulls.assign(cleaned_end_station_name=cleaned_end_station_name)\n",
        "print(\"Sample of 'end_station_id' after NULL handling:\")\n",
        "display(sample_df_nulls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "i8-LEoCmrDu2",
        "outputId": "ee61b961-4d64-4b96-8447-44672679b4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3.1 Handling NULLs: `end_station_id` ---\n",
            "Sample of 'end_station_id' after NULL handling:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 06866c55-7606-4a86-bc14-2f11f145b2ae is DONE. 72.1 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=vinodpatel05-handson-project&j=bq:US:06866c55-7606-4a86-bc14-2f11f145b2ae&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      trip_id end_station_id cleaned_end_station_name\n",
              "27   28384660           <NA>       UNKNOWN_STATION_ID\n",
              "28   28499231           <NA>       UNKNOWN_STATION_ID\n",
              "91   28392701           <NA>       UNKNOWN_STATION_ID\n",
              "115  28486724           <NA>       UNKNOWN_STATION_ID\n",
              "290  28404131           <NA>       UNKNOWN_STATION_ID\n",
              "\n",
              "[5 rows x 3 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trip_id</th>\n",
              "      <th>end_station_id</th>\n",
              "      <th>cleaned_end_station_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28384660</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>UNKNOWN_STATION_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28499231</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>UNKNOWN_STATION_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>28392701</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>UNKNOWN_STATION_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>28486724</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>UNKNOWN_STATION_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>28404131</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "      <td>UNKNOWN_STATION_ID</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3 columns</p>\n",
              "</div>[5 rows x 3 columns in total]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Trimming Whitespace and Standardizing Case: `subscriber_type`\n",
        "String values often benefit from trimming leading/trailing whitespace and standardizing casing (e.g., all uppercase or all lowercase) to ensure consistency."
      ],
      "metadata": {
        "id": "ixl0UX-crTy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3.2 Trimming Whitespace and Standardizing Case: `subscriber_type` ---\")\n",
        "\n",
        "# Apply string operations\n",
        "standardized_subscriber_type = df['subscriber_type'].str.strip().str.upper()\n",
        "\n",
        "# Display a sample\n",
        "sample_df_strings = df[['trip_id', 'subscriber_type']].head(5)\n",
        "sample_df_strings = sample_df_strings.assign(standardized_subscriber_type=standardized_subscriber_type)\n",
        "print(\"Sample of 'subscriber_type' after trimming and uppercasing:\")\n",
        "print(sample_df_strings.to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJVl_9A2rPfd",
        "outputId": "da0f82e6-64ce-4d6a-fc55-090b7c529567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3.2 Trimming Whitespace and Standardizing Case: `subscriber_type` ---\n",
            "Sample of 'subscriber_type' after trimming and uppercasing:\n",
            "|   trip_id | subscriber_type         | standardized_subscriber_type   |\n",
            "|----------:|:------------------------|:-------------------------------|\n",
            "|   2589756 | 24 Hour Walk Up Pass    | 24 HOUR WALK UP PASS           |\n",
            "|   3913263 | 24 Hour Walk Up Pass    | 24 HOUR WALK UP PASS           |\n",
            "|  16769997 | U.T. Student Membership | U.T. STUDENT MEMBERSHIP        |\n",
            "|  10470370 | Local365                | LOCAL365                       |\n",
            "|  28581115 | 3-Day Weekender         | 3-DAY WEEKENDER                |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  3.3 Type Casting and Data Format Validation: `bikeid` (Illustrative)\n",
        "Sometimes, numeric data might be stored as strings with inconsistent formatting or non-numeric characters."
      ],
      "metadata": {
        "id": "Vq7XVaaaranL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample DataFrame with invalid data for a clear demonstration\n",
        "sample_pandas_df = pd.DataFrame({\n",
        "    'trip_id': [101, 102, 103, 104, 105],\n",
        "    'bike_id': [9331, 12921, 99999, 13271, 4255], # Original numeric IDs\n",
        "    'bike_id_as_string': [\"9331\", \"12921\", \"not-a-bike\", \"13271\", \"4255A\"], # String version with errors\n",
        "})\n",
        "\n",
        "# Copy the local pandas DataFrame to a BigQuery DataFrame\n",
        "# This creates a reference to a table in BigQuery without moving all the data immediately\n",
        "df_simulated = bf.read_pandas(sample_pandas_df)\n",
        "\n",
        "\n",
        "print(\"\\n--- 3.3 Type Casting and Data Format Validation: `bike_id` ---\")\n",
        "\n",
        "# --- CORRECTED & SIMPLIFIED APPROACH ---\n",
        "\n",
        "# 1. Create a boolean mask to identify strings that consist only of digits.\n",
        "# The .str.fullmatch(r'\\d+') method checks if the entire string matches the pattern for one or more digits.\n",
        "is_numeric_mask = df_simulated['bike_id_as_string'].str.fullmatch(r'\\d+')\n",
        "\n",
        "# 2. Create the validation status column based on the mask.\n",
        "# Where the mask is True (it's a valid number string), the status is 'Valid'. Otherwise, it's 'Invalid Format'.\n",
        "validation_status = is_numeric_mask.where('Valid', 'Invalid Format')\n",
        "\n",
        "# 3. Create the casted column.\n",
        "# First, use the mask to replace non-numeric strings with NA (which becomes NULL in BigQuery).\n",
        "# Then, safely cast the column to a nullable integer type 'Int64'. This now works because all invalid formats are gone.\n",
        "casted_bike_id = df_simulated['bike_id_as_string'].where(is_numeric_mask).astype(\"Int64\")\n",
        "\n",
        "# 4. Assign the new columns to the DataFrame for the final display.\n",
        "# We are creating a new DataFrame that includes the original columns plus our new ones.\n",
        "df_final_display = df_simulated.assign(\n",
        "    casted_bike_id=casted_bike_id,\n",
        "    validation_status=validation_status\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\nSample of 'bike_id' after type casting and validation:\")\n",
        "# Display the final result as markdown.\n",
        "# The .to_pandas() method executes the query in BigQuery and brings the results back.\n",
        "print(df_final_display.to_pandas().to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3pYbwwDrWdS",
        "outputId": "fc9c839d-0593-4df9-9998-a51b92a52584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3.3 Type Casting and Data Format Validation: `bike_id` ---\n",
            "\n",
            "Sample of 'bike_id' after type casting and validation:\n",
            "|   trip_id |   bike_id | bike_id_as_string   | casted_bike_id   | validation_status   |\n",
            "|----------:|----------:|:--------------------|:-----------------|:--------------------|\n",
            "|       101 |      9331 | 9331                | 9331             | True                |\n",
            "|       102 |     12921 | 12921               | 12921            | True                |\n",
            "|       103 |     99999 | not-a-bike          | <NA>             | False               |\n",
            "|       104 |     13271 | 13271               | 13271            | True                |\n",
            "|       105 |      4255 | 4255A               | <NA>             | False               |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Uniqueness Check: `trip_id` (Primary Key)\n",
        "Validating primary keys ensures that each record is uniquely identifiable."
      ],
      "metadata": {
        "id": "UfikO4Jk1FRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3.4 Uniqueness Check: `trip_id` (Primary Key) ---\")\n",
        "\n",
        "# Check for duplicates. `duplicated(keep=False)` marks all occurrences of a duplicate.\n",
        "duplicate_trip_ids = df[df['trip_id'].duplicated(keep=False)]\n",
        "\n",
        "if duplicate_trip_ids.empty:\n",
        "    print(\"No duplicate 'trip_id' found. Column is unique.\")\n",
        "else:\n",
        "    print(\"Duplicate 'trip_id' found (showing counts):\")\n",
        "    print(duplicate_trip_ids[['trip_id']].value_counts().to_markdown())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF-1kzVQzvsk",
        "outputId": "84765f54-037a-4ba2-d1d9-d8b921323c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3.4 Uniqueness Check: `trip_id` (Primary Key) ---\n",
            "No duplicate 'trip_id' found. Column is unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3.5 Referential Integrity Check: `start_station_id` (Illustrative)\n",
        "Referential integrity ensures that foreign key values in one table correctly reference existing primary key values in another (master) table.\n",
        "**NOTE**: This is an illustrative example. The public `austin_bikeshare` dataset does not have a direct master station table within the same dataset that we can easily join to. In a real scenario, you would load your actual master station table into another `bigframes` DataFrame and perform a join."
      ],
      "metadata": {
        "id": "UkrRBx5p1QT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3.5 Referential Integrity Check: `start_station_id` (Illustrative) ---\")\n",
        "\n",
        "# For this public dataset, we'll demonstrate using a hypothetical list of known valid station IDs.\n",
        "# In a real scenario, you'd load these from a master table (e.g., `bf.read_gbq_table('your_master_stations_table')`).\n",
        "known_valid_station_ids = bf.Series([2501, 2502, 2503, 2504, 2505, 2506, 2507, 2508, 2509, 2510]) # Hypothetical valid IDs\n",
        "\n",
        "# Find start_station_ids that are NOT in our hypothetical list of known valid IDs\n",
        "invalid_start_station_ids = df[~df['start_station_id'].isin(known_valid_station_ids)]\n",
        "\n",
        "if invalid_start_station_ids.empty:\n",
        "    print(\"No missing 'start_station_id' found (based on illustrative valid IDs).\")\n",
        "else:\n",
        "    print(\"Invalid 'start_station_id' found (not in hypothetical valid list):\")\n",
        "    print(invalid_start_station_ids[['trip_id', 'start_station_id']].head(10).to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-PyPxm01I83",
        "outputId": "72a09300-816c-4bcb-c706-87945d4658be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3.5 Referential Integrity Check: `start_station_id` (Illustrative) ---\n",
            "Invalid 'start_station_id' found (not in hypothetical valid list):\n",
            "|   trip_id |   start_station_id |\n",
            "|----------:|-------------------:|\n",
            "|   2589756 |               2574 |\n",
            "|  16769997 |               2547 |\n",
            "|  10470370 |               3292 |\n",
            "|  28581115 |               4058 |\n",
            "|  17397208 |               3794 |\n",
            "|  22213927 |               3455 |\n",
            "|  18348656 |               3790 |\n",
            "|  29350073 |               7189 |\n",
            "|  23542490 |               3838 |\n",
            "|  15842522 |               2570 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bigframes/dataframe.py:4404: FutureWarning: Starting with pandas version 3.0 all arguments of to_markdown except for the argument 'buf' will be keyword-only.\n",
            "  return self.to_pandas(allow_large_results=allow_large_results).to_markdown(buf, mode, index, **kwargs)  # type: ignore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wrap Up\n",
        "\n",
        "This notebook demonstrates how to leverage `bigframes` to perform essential data quality tasks directly within BigQuery. By using a pandas-like interface, you can efficiently profile your data, detect anomalies, and apply cleansing and validation rules at scale.\n"
      ],
      "metadata": {
        "id": "eD3PlbZC1iom"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cFB5VQABlL-i"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}